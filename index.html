<!DOCTYPE HTML>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Ankith Jain Rakesh Kumar</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
  <style>
    body {
      font-family: 'Segoe UI', sans-serif;
      margin: 0;
      background: #fafafa;
      color: #333;
    }
    header {
      background: #003366;
      color: white;
      padding: 30px 20px;
      text-align: center;
    }
    header h1 {
      margin-bottom: 10px;
    }
    .container {
      max-width: 960px;
      margin: auto;
      padding: 30px;
    }
    h2 {
      color: #003366;
      border-bottom: 2px solid #ddd;
      padding-bottom: 5px;
    }
    ul, ol {
      padding-left: 20px;
    }
    .pub-entry {
      margin-bottom: 20px;
    }
    .pub-entry b {
      color: #0a4d8c;
    }
    .contact {
      text-align: center;
      margin-top: 15px;
    }
    .contact a {
      margin: 0 10px;
      text-decoration: none;
      color: #003366;
      font-weight: bold;
    }
    footer {
      text-align: center;
      padding: 15px;
      background: #003366;
      color: white;
    }
  </style>
</head>
<body>
  <header>
    <h1>Ankith Jain Rakesh Kumar</h1>
    <p>Ph.D. Candidate | Computer Vision | Graph Neural Networks | Biomedical AI</p>
    <div class="contact">
      <a href="mailto:arake001@ucr.edu"><i class="fas fa-envelope"></i> Email</a>
      <a href="CV.pdf"><i class="fas fa-file"></i> CV</a>
      <a href="https://scholar.google.com/citations?user=YC2Sk78AAAAJ&hl=en"><i class="fas fa-graduation-cap"></i> Scholar</a>
      <a href="https://www.linkedin.com/in/ankith-jain-rk"><i class="fab fa-linkedin"></i> LinkedIn</a>
    </div>
  </header>

  <div class="container">
    <section>
      <h2>About Me</h2>
      <p>I am a final-year Ph.D. student in Electrical and Computer Engineering at the University of California, Riverside. I work with Prof. Bir Bhanu at the Visualization and Intelligent Systems Lab (VisLab). My research focuses on graph-based deep learning, medical image analysis, micro-expression recognition, and multi-modal fusion using attention-based architectures.</p>
    </section>

    <section>
      <h2>Research Interests</h2>
      <ul>
        <li>Graph Neural Networks (GNNs)</li>
        <li>Facial Micro-Expression Analysis</li>
        <li>Medical Imaging and Radiology AI</li>
        <li>Vision Transformers & Graph Transformers</li>
        <li>Multimodal Fusion (Image + Gaze + Text)</li>
        <li>Diffusion Models</li>
        <li>Self-Supervised Learning</li>
        <li>Efficient Video Understanding</li>
        <li>Generative AI in Healthcare</li>
      </ul>
    </section>

    <section>
      <h2>Publications</h2>
      <ol>
        <li class="pub-entry"><b>Dirichlet-Energy-Guided GNNs</b> — Ankith Jain Rakesh Kumar, Bir Bhanu. <i>(Under Submission)</i></li>
        <li class="pub-entry"><b>From Fixation to Diagnosis: Attention-Guided Graph Fusion for Chest X-ray</b> — <i>IEEE TMI</i>, Under Review</li>
        <li class="pub-entry"><b>Masked Graph Attention Network for Facial Micro-Expression</b> — <i>Image and Vision Computing</i>, Under Revision</li>
        <li class="pub-entry"><b>Micro-Expression Classification with Weighted Graph Network</b> — <i>IEEE T-BIOM</i></li>
        <li class="pub-entry"><b>Adaptive Multi-Attention GNNs</b> — <i>CVPR Workshop on ABAW</i>, 2024</li>
        <li class="pub-entry"><b>Relational Edge-Node Graph Attention Network</b> — <i>CVPR Workshop on ABAW</i>, 2023</li>
        <li class="pub-entry"><b>Three-Stream Graph Attention Network with Dynamic Patch Selection</b> — <i>CVPR Workshop on ABAW</i>, 2022</li>
        <li class="pub-entry"><b>Landmark-Based Graph Convolutional Network for Micro-Expressions</b> — <i>CVPR Workshop</i>, 2021</li>
        <li class="pub-entry"><b>Depth Videos for Micro-Expressions</b> — <i>ICPR</i>, 2021</li>
        <li class="pub-entry"><b>Motion Magnified Emotion Avatar Images</b> — <i>CVPR Workshop on FG-AHI</i>, 2019</li>
      </ol>
    </section>

    <section>
      <h2>Research Experience</h2>
      <ul>
        <li><b>UC Riverside, Graduate Student Researcher (2019–Present)</b><br>
        Developed MaskGAT, Gaze-Guided Transformers, and Dirichlet-based GNNs for facial expression, medical image, and molecule datasets.</li>
        <li><b>UC Riverside, Graduate Research Assistant (2017–2018)</b><br>
        Worked on WCET analysis of DNNs and sensor fusion using LiDAR and IMU for autonomous systems.</li>
        <li><b>Dayananda Sagar College, Research Assistant (2014–2016)</b><br>
        Built fingerprint-based access systems and object detection using optical flow and GMM.</li>
      </ul>
    </section>

    <section>
      <h2>Teaching & Mentorship</h2>
      <ul>
        <li><b>Instructor</b>: Data Analysis (2024–2025), Linear Algebra (2023), AI Summer Camp (2022–2025)</li>
        <li><b>TA</b>: Computer Vision, Computational Learning, Circuits I & II, Embedded Systems</li>
        <li><b>Mentor</b>: Omar Peraza, Qifeng Zhao, Malhar Thombare</li>
      </ul>
    </section>

    <section>
      <h2>Honors & Activities</h2>
      <ul>
        <li><b>Fellowship</b>: UCR Graduate Dean's Fellowship (2019)</li>
        <li><b>Reviewer</b>: CVPR, ICPR, IEEE THMS, Image and Vision Computing</li>
      </ul>
    </section>

    <section>
      <h2>Technical Skills</h2>
      <ul>
        <li><b>Programming</b>: Python, C, SQL, R, MATLAB</li>
        <li><b>Libraries</b>: PyTorch, TensorFlow, Keras, Scikit-learn, OpenCV, NumPy, Pandas</li>
        <li><b>Specialties</b>: GNNs, Vision Transformers, Multimodal Learning, Diffusion Models, Biomedical AI</li>
        <li><b>Tools</b>: Linux, Git, VSCode, Jupyter, LaTeX</li>
      </ul>
    </section>
  </div>

  <footer>
    &copy; 2025 Ankith Jain Rakesh Kumar | Website inspired by Jon Barron
  </footer>
</body>
</html>
