<!DOCTYPE HTML>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Ankith Jain Rakesh Kumar</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
  <style>
    body {
      font-family: 'Segoe UI', sans-serif;
      margin: 0;
      background: #fafafa;
      color: #333;
    }
    header {
      background: #003366;
      color: white;
      padding: 30px 20px;
      text-align: center;
    }
    header h1 {
      margin-bottom: 10px;
    }
    .container {
      max-width: 960px;
      margin: auto;
      padding: 30px;
    }
    h2 {
      color: #003366;
      border-bottom: 2px solid #ddd;
      padding-bottom: 5px;
    }
    ul, ol {
      padding-left: 20px;
    }
    .pub-entry {
      margin-bottom: 20px;
    }
    .pub-entry a {
      color: #0a4d8c;
      text-decoration: none;
    }
    .pub-entry a:hover {
      text-decoration: underline;
    }
    .contact {
      text-align: center;
      margin-top: 15px;
    }
    .contact a {
      margin: 0 10px;
      text-decoration: none;
      color: #ffffff;
      font-weight: bold;
    }
    footer {
      text-align: center;
      padding: 15px;
      background: #003366;
      color: white;
    }
    .profile-img {
      width: 150px;
      border-radius: 50%;
      margin: 20px auto;
      display: block;
    }
  </style>
</head>
<body>
  <header>
    <img src="ankith.jpg" alt="Ankith Jain Rakesh Kumar" class="profile-img">
    <h1>Ankith Jain Rakesh Kumar</h1>
    <p>Ph.D. Candidate | Computer Vision | Graph Neural Networks | Biomedical AI</p>
    <div class="contact">
      <a href="mailto:arake001@ucr.edu"><i class="fas fa-envelope"></i> Email</a>
      <a href="Resume_25.pdf"><i class="fas fa-file"></i> CV</a>
      <a href="https://scholar.google.com/citations?user=YC2Sk78AAAAJ&hl=en"><i class="fas fa-graduation-cap"></i> Scholar</a>
      <a href="https://www.linkedin.com/in/ankith-jain-rakesh-kumar/"><i class="fab fa-linkedin"></i> LinkedIn</a>
    </div>
  </header>

  <div class="container">
    <section>
      <h2>About Me</h2>
      <p>I am a final-year Ph.D. student in Electrical and Computer Engineering at the University of California, Riverside. I work with Prof. Bir Bhanu at the Visualization and Intelligent Systems Lab (VisLab). My research focuses on graph-based deep learning, medical image analysis, micro-expression recognition, and multi-modal fusion using attention-based architectures.</p>
    </section>

    <section>
      <h2>Research Interests</h2>
      <ul>
        <li>Graph Neural Networks (GNNs)</li>
        <li>Facial Micro-Expression Analysis</li>
        <li>Medical Imaging and Radiology AI</li>
        <li>Vision Transformers & Graph Transformers</li>
        <li>Multimodal Fusion (Image + Gaze + Text)</li>
        <li>Diffusion Models</li>
        <li>Self-Supervised Learning</li>
        <li>Efficient Video Understanding</li>
        <li>Generative AI in Healthcare</li>
      </ul>
    </section>

    <section>
      <h2>Publications</h2>
      <ol>
        <li class="pub-entry"><a href="#"><b>Dirichlet-Energy-Guided GNNs with Dynamic Weighting for Molecular and Protein Graphs</b></a> — Ankith Jain Rakesh Kumar, Bir Bhanu. <i>(Under Submission)</i></li>
        <li class="pub-entry"><a href="#"><b>From Fixation to Diagnosis: Attention-Guided Graph Fusion for Chest X-ray Diagnosis</b></a> — <i>IEEE Transactions on Medical Imaging</i>, Under Review</li>
        <li class="pub-entry"><a href="https://www.sciencedirect.com/science/article/abs/pii/S0262885625001726"><b>Masked Graph Attention Network for Classification of Facial Micro-Expression</b></a> — <i>Image and Vision Computing</i>
        <li class="pub-entry"><a href="https://ieeexplore.ieee.org/abstract/document/10922210"><b>Micro-Expression Classification With Weighted Locally Constrained Graph Network</b></a> — <i>IEEE Transactions on Biometrics, Behavior, and Identity Science</i></li>
        <li class="pub-entry"><a href="https://openaccess.thecvf.com/content/CVPR2024W/ABAW/papers/Kumar_Uncovering_Hidden_Emotions_with_Adaptive_Multi-Attention_Graph_Networks_CVPRW_2024_paper.pdf"><b>Uncovering Hidden Emotions with Adaptive Multi-Attention Graph Networks</b></a> — <i>CVPR Workshop on ABAW</i>, 2024</li>
        <li class="pub-entry"><a href="https://openaccess.thecvf.com/content/CVPR2023W/ABAW/papers/Kumar_Relational_Edge-Node_Graph_Attention_Network_for_Classification_of_Micro-Expressions_CVPRW_2023_paper.pdf"><b>Relational Edge-Node Graph Attention Network for Classification of Micro-Expressions</b></a> — <i>CVPR Workshop on ABAW</i>, 2023</li>
        <li class="pub-entry"><a href="https://openaccess.thecvf.com/content/CVPR2022W/ABAW/papers/Kumar_Three_Stream_Graph_Attention_Network_Using_Dynamic_Patch_Selection_for_CVPRW_2022_paper.pdf"><b>Three Stream Graph Attention Network using Dynamic Patch Selection for the Classification of Micro-Expressions</b></a> — <i>CVPR Workshop on ABAW</i>, 2022</li>
        <li class="pub-entry"><a href="https://openaccess.thecvf.com/content/CVPR2021W/AMFG/papers/Kumar_Micro-Expression_Classification_Based_on_Landmark_Relations_With_Graph_Attention_Convolutional_CVPRW_2021_paper.pdf"><b>Micro-Expression Classification based on Landmark Relations with Graph Attention Convolutional Network</b></a> — <i>CVPR Workshop on AMFG</i>, 2021</li>
        <li class="pub-entry"><a href="https://ieeexplore.ieee.org/abstract/document/9412976"><b>Depth Videos for the Classification of Micro-Expressions</b></a> — <i>ICPR</i>, 2021</li>
        <li class="pub-entry"><a href="https://openaccess.thecvf.com/content_CVPRW_2019/papers/Face%20and%20Gesture%20Analysis%20for%20Health%20Informatics/Kumar_CLASSIFICATION_OF_FACIAL_MICRO-EXPRESSIONS_USING_MOTION_MAGNIFIED_EMOTION_AVATAR_IMAGES_CVPRW_2019_paper.pdf"><b>Classification of Facial Micro-Expressions using Motion Magnified Emotion Avatar Images</b></a> — <i>CVPR Workshop on FG-AHI</i>, 2019</li>
      </ol>
    </section>

    <section>
      <h2>Research Experience</h2>
      <ul>
        <li><b>UC Riverside, Graduate Student Researcher (2019–Present)</b><br>
        Developed MaskGAT, Weighted Locally Constrained Graph Networks, Gaze-Guided Transformers, and Dirichlet-based GNNs for facial expression, medical image, and molecule datasets.</li>
        <li><b>UC Riverside, Graduate Research Assistant (2017–2018)</b><br>
        Worked on WCET analysis of DNNs and sensor fusion using LiDAR and IMU for autonomous systems.</li>
        <li><b>Dayananda Sagar College, Research Assistant (2014–2016)</b><br>
        Built fingerprint-based access systems and object detection using optical flow and GMM.</li>
      </ul>
    </section>

    <section>
      <h2>Teaching & Mentorship</h2>
      <ul>
        <li><b>Instructor</b>: Data Analysis (2024–2025), Linear Algebra (2023), AI Summer Camp (2022–2025)</li>
        <li><b>TA</b>: Computer Vision, Computational Learning, Circuits I & II, Embedded Systems</li>
        <li><b>Mentor</b>: Omar Peraza, Qifeng Zhao, Malhar Thombare</li>
      </ul>
    </section>

    <section>
      <h2>Honors & Activities</h2>
      <ul>
        <li><b>Fellowship</b>: UCR Graduate Dean's Fellowship (2019)</li>
        <li><b>Reviewer</b>: CVPR, ICPR, IEEE THMS, Image and Vision Computing</li>
      </ul>
    </section>

    <section>
      <h2>Technical Skills</h2>
      <ul>
        <li><b>Programming</b>: Python, C, SQL, R, MATLAB</li>
        <li><b>Libraries</b>: PyTorch, TensorFlow, Keras, Scikit-learn, OpenCV, NumPy, Pandas</li>
        <li><b>Specialties</b>: GNNs, Vision Transformers, Multimodal Learning, Diffusion Models, Biomedical AI</li>
        <li><b>Tools</b>: Linux, Git, VSCode, Jupyter, LaTeX</li>
      </ul>
    </section>
  </div>

  <footer>
    &copy; 2025 Ankith Jain Rakesh Kumar | Website inspired by Jon Barron
  </footer>
</body>
</html>
